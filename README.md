# Natural Language Queries for Egocentric Vision

This repository contains the code associated with the Advanced Machine Learning course final project.

## Authors
- [Utku Kepir](https://github.com/UtkuKepir)
- [Meric Ulucay](https://github.com/mericuluca)
- [Anil Bayram Gogebakan](https://github.com/anilbayramgogebakan)

## Setting the code and environnment
For running Llama model, envirenment can be set with singularity container. Use [llama.def](llama.def) definition file to build the container.

```sh
singularity build --fakeroot llama.sif llama.def
```

This command will generate llama.sif file. By using this, Llama related scripts should be runnable. Start container with following command.

```sh
singularity shell --nv llama.sif
```

For other parts of the project, Colab environment used. Thus, required commands are in the file itself.

## Generating queries

converter.py script generate new queries by using Llama model. It takes input folder path where narratations json files exist and generate output folder with NLQ-like queries. In the existing setup Llama3.2-3B-Instruct model is used. However, different Llama models can be used as well. In order to run this script, run_converter.sh must used. Inputs must be in the format that generated by [this](./src/Colab_scripts/gen_llama_input_and_editing_llama_output.ipynb).

```sh
sh run_converter.sh
```

## Training the models
Models trained on Colab envirenment as mentioned. First, different model variations are trained with using original dataset by using this [script](./src/Colab_scripts/Ego4D_NLQ_Benchmark_trainNET&BASEwithBERT_trainNetwithGLOVE.ipynb). After new queries generated by Llama, another [script](./src/Colab_scripts/gen_llama_input_and_editing_llama_output.ipynb) converts them to desired format and merged it with the existing dataset. Finally, model is trained with the new aggregeated dataset by using this [script](./src/Colab_scripts/Ego4D_NLQ_Benchmark_finetune.ipynb).
